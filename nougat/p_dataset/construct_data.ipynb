{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check and save arxiv_all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "os.chdir('/mnt/data/ai4phys/sunyu/nougat')\n",
    "save_fold = 'arxiv_all_files3'\n",
    "arxiv_all_files = os.listdir(f'data/{save_fold}')\n",
    "with open(f'data/pdf_list/{save_fold}.txt','w') as fi:\n",
    "    fi.writelines([fold+'\\n' for fold in arxiv_all_files])\n",
    "len(arxiv_all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11245\n"
     ]
    }
   ],
   "source": [
    "# read arxiv_all_files\n",
    "import os\n",
    "os.chdir('/mnt/data/ai4phys/sunyu/nougat')\n",
    "save_fold = 'arxiv_all_files3'\n",
    "with open(f'data/pdf_list/{save_fold}.txt','r')as fi:\n",
    "    arxiv_all_files = fi.read().splitlines()\n",
    "print(len(arxiv_all_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1263122"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data/pdf_list/latex_dir.txt','r') as fi:\n",
    "    tex_folds = fi.readlines()\n",
    "tex_folds = [t.strip() for t in tex_folds]\n",
    "len(tex_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3755 0.0751\n"
     ]
    }
   ],
   "source": [
    "# latex\n",
    "count=0\n",
    "for i in range(760000,810000):\n",
    "    if tex_folds[i] in arxiv_all_files:\n",
    "        count += 1\n",
    "print(count,count/(810000-760000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4674 0.11685\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# latex2\n",
    "count=0\n",
    "for i in range(810000,850000):\n",
    "    if tex_folds[i] in arxiv_all_files:\n",
    "        count += 1\n",
    "print(count,count/(850000-810000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6011 0.0751375\n"
     ]
    }
   ],
   "source": [
    "# latex3\n",
    "count=0\n",
    "for i in range(850000,930000):\n",
    "    if tex_folds[i] in arxiv_all_files:\n",
    "        count += 1\n",
    "print(count,count/(930000-850000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2834 0.07085\n"
     ]
    }
   ],
   "source": [
    "# latex4\n",
    "count=0\n",
    "for i in range(930000,970000):\n",
    "    if tex_folds[i] in arxiv_all_files:\n",
    "        count += 1\n",
    "print(count,count/(970000-930000))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取tex_fold/train.jsonl并合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "def combine_data(tex_fold,save_fold_idx='3'):\n",
    "    if os.path.exists(f'data/arxiv_all_files{save_fold_idx}/{tex_fold}/train.jsonl') and os.path.exists(f'data/arxiv_all_files{save_fold_idx}/{tex_fold}/png'):\n",
    "        with open(f'data/arxiv_all_files{save_fold_idx}/{tex_fold}/train.jsonl','r') as fi:\n",
    "            lines = fi.read()\n",
    "        for png_file in os.listdir(f'data/arxiv_all_files{save_fold_idx}/{tex_fold}/png'):\n",
    "            subprocess.run(['cp','-n',f'data/arxiv_all_files{save_fold_idx}/{tex_fold}/png/{png_file}',f'data/arxiv_train_data/png/{tex_fold}_{png_file}'])\n",
    "            # png改为相对路径\n",
    "            lines = lines.replace(f'data/arxiv_color/{tex_fold}/png/{png_file}',f'png/{tex_fold}_{png_file}')\n",
    "            # mask处理：编码为-1，在encoding时不加position_embedding\n",
    "            lines = lines.replace('[\"mask\"]','[[-1,-1],[-1,-1]]')\n",
    "        with open(f'data/arxiv_train_data/train_color{save_fold_idx}.jsonl','a') as fo:\n",
    "            fo.write(lines)\n",
    "    elif os.path.exists(f'data/arxiv_all_files{save_fold_idx}/{tex_fold}/train_black.jsonl') and os.path.exists(f'data/arxiv_all_files{save_fold_idx}/{tex_fold}/png'):\n",
    "        with open(f'data/arxiv_all_files{save_fold_idx}/{tex_fold}/train_black.jsonl','r') as fi:\n",
    "            lines = fi.read() \n",
    "        for png_file in os.listdir(f'data/arxiv_all_files{save_fold_idx}/{tex_fold}/png'):\n",
    "            subprocess.run(['cp','-n',f'data/arxiv_all_files{save_fold_idx}/{tex_fold}/png/{png_file}',f'data/arxiv_train_data/png/{tex_fold}_{png_file}'])\n",
    "            # png改为相对路径\n",
    "            lines = lines.replace(f'data/arxiv_origin/{tex_fold}/png/{png_file}',f'png/{tex_fold}_{png_file}')\n",
    "            # mask处理：编码为-1，在encoding时不加position_embedding\n",
    "            lines = lines.replace('[\"mask\"]','[[-1,-1],[-1,-1]]')\n",
    "        with open(f'data/arxiv_train_data/train_black{save_fold_idx}.jsonl','a') as fo:\n",
    "            fo.write(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor,ProcessPoolExecutor\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=8) as pool:  \n",
    "    inputs = arxiv_all_files\n",
    "    futures = pool.map(combine_data, inputs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process color lines\n",
    "import json\n",
    "import re\n",
    "save_fold_idx='2'\n",
    "with open(f'data/arxiv_train_data/train_color{save_fold_idx}.jsonl','r') as fi:\n",
    "    lines = fi.readlines()\n",
    "for i,line in enumerate(lines):\n",
    "    dct = json.loads(line)\n",
    "    for idx in range(len(dct['prompt'])):\n",
    "        if dct['prompt'][idx] != [[-1,-1],[-1,-1]]:   # 找到第一个非'mask'位置\n",
    "            break\n",
    "    # 去掉开头多余符号\n",
    "    if idx>0 and idx<len(dct['prompt'])-1:\n",
    "        if '#' in dct['pretext'][idx-1]:   # 保留标题\n",
    "            dct['prompt'] = dct['prompt'][idx-1:]\n",
    "            dct['pretext'] = dct['pretext'][idx-1:]\n",
    "        elif idx>=2 and ('#' in dct['pretext'][idx-2] or re.search(r'figure|table',dct['pretext'][idx-2],re.I)):   # 保留图表头\n",
    "            dct['prompt'] = dct['prompt'][idx-2:]\n",
    "            dct['pretext'] = dct['pretext'][idx-2:]\n",
    "        else:\n",
    "            dct['prompt'] = dct['prompt'][idx:]\n",
    "            dct['pretext'] = dct['pretext'][idx:]\n",
    "    lines[i] = json.dumps(dct)+'\\n'\n",
    "with open(f'data/arxiv_train_data/train_color{save_fold_idx}.jsonl','w') as fo:\n",
    "    fo.writelines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process black lines\n",
    "import json\n",
    "save_fold_idx='2'\n",
    "with open(f'data/arxiv_train_data/train_black{save_fold_idx}.jsonl','r') as fi:\n",
    "    lines = fi.readlines()\n",
    "for i,line in enumerate(lines):\n",
    "    dct = json.loads(line)\n",
    "    dct['pretext'] = [dct['pretext']]\n",
    "    dct['prompt'] = [dct['prompt']]\n",
    "    lines[i] = json.dumps(dct)+'\\n'\n",
    "with open(f'data/arxiv_train_data/train_black{save_fold_idx}.jsonl','w') as fo:\n",
    "    fo.writelines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct train.jsonl val.jsonl\n",
    "import random\n",
    "save_fold_idx='2'\n",
    "with open(f'data/arxiv_train_data/train_color{save_fold_idx}.jsonl','r') as fi:\n",
    "    color_lines = fi.readlines()\n",
    "with open(f'data/arxiv_train_data/train_black{save_fold_idx}.jsonl','r') as fi:\n",
    "    black_lines = fi.readlines()\n",
    "total = 2*len(color_lines)\n",
    "train,val = int(0.8*total),int(0.2*total)\n",
    "train_lines = color_lines[:int(train/2)]+black_lines[:int(train/2)]\n",
    "val_lines = color_lines[int(train/2):]+black_lines[int(train/2):int(total/2)]\n",
    "random.shuffle(train_lines)\n",
    "random.shuffle(val_lines)\n",
    "with open(f'data/arxiv_train_data/train{save_fold_idx}.jsonl','w') as fo:\n",
    "    fo.writelines(train_lines)\n",
    "with open(f'data/arxiv_train_data/validation{save_fold_idx}.jsonl','w') as fo:\n",
    "    fo.writelines(val_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9403\n",
      "8978\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "save_fold_idx='3'\n",
    "os.chdir('/mnt/data/ai4phys/sunyu/nougat')\n",
    "with open(f'data/arxiv_train_data/train_color{save_fold_idx}.jsonl','r') as fi:\n",
    "    print(len(fi.readlines()))\n",
    "with open(f'data/arxiv_train_data/train_black{save_fold_idx}.jsonl','r') as fi:\n",
    "    print(len(fi.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05220969379575696"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "train = 182328+39586+15460\n",
    "(2326-4280)/(24290-61716)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove useless folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4280 8027\n"
     ]
    }
   ],
   "source": [
    "# remove bugs\n",
    "import subprocess\n",
    "import json\n",
    "# train0.jsonl:0-34w = 9/34 = 0.26\n",
    "# train1.jsonl:34-55w = 4/21 = 0.1\n",
    "# train2.jsonl:55-76w = 0.8/21 = 0.03\n",
    "# train3.jsonl:76-97w\n",
    "save_fold_idx='3'\n",
    "color_folds=0\n",
    "black_folds=0\n",
    "for tex_fold in tex_folds[760000:970000]:\n",
    "    if os.path.exists(f'data/arxiv_all_files{save_fold_idx}/{tex_fold}'):\n",
    "        if os.path.exists(f'data/arxiv_all_files{save_fold_idx}/{tex_fold}/train.jsonl'):\n",
    "            color_folds += 1\n",
    "            continue\n",
    "        elif os.path.exists(f'data/arxiv_all_files{save_fold_idx}/{tex_fold}/train_black.jsonl'):\n",
    "            black_folds += 1\n",
    "            continue\n",
    "        # else:\n",
    "        #     os.system(f'rm -r data/arxiv_all_files{save_fold_idx}/{tex_fold}')\n",
    "print(color_folds,black_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
