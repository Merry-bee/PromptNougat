{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check and save arxiv_all_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5833"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "os.chdir('/mnt/data/ai4phys/sunyu/nougat')\n",
    "save_fold = 'arxiv_all_files3'\n",
    "arxiv_all_files = os.listdir(f'data/{save_fold}')\n",
    "with open(f'data/pdf_list/{save_fold}.txt','w') as fi:\n",
    "    fi.writelines([fold+'\\n' for fold in arxiv_all_files])\n",
    "len(arxiv_all_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "204781\n"
     ]
    }
   ],
   "source": [
    "# read arxiv_all_files\n",
    "import os\n",
    "os.chdir('/mnt/data/ai4phys/sunyu/nougat')\n",
    "save_fold = 'arxiv_all_files2'\n",
    "with open(f'data/pdf_list/{save_fold}.txt','r')as fi:\n",
    "    arxiv_all_files = fi.read().splitlines()\n",
    "print(len(arxiv_all_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1263122"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data/pdf_list/latex_dir.txt','r') as fi:\n",
    "    tex_folds = fi.readlines()\n",
    "tex_folds = [t.strip() for t in tex_folds]\n",
    "len(tex_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49079 0.98158\n"
     ]
    }
   ],
   "source": [
    "# latex\n",
    "count=0\n",
    "for i in range(550000,600000):\n",
    "    if tex_folds[i] in arxiv_all_files:\n",
    "        count += 1\n",
    "print(count,count/(600000-550000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39435 0.985875\n"
     ]
    }
   ],
   "source": [
    "# latex2\n",
    "count=0\n",
    "for i in range(600000,640000):\n",
    "    if tex_folds[i] in arxiv_all_files:\n",
    "        count += 1\n",
    "print(count,count/(640000-600000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "78157 0.9769625\n"
     ]
    }
   ],
   "source": [
    "# latex3\n",
    "count=0\n",
    "for i in range(640000,720000):\n",
    "    if tex_fold[i] in arxiv_all_files:\n",
    "        count += 1\n",
    "print(count,count/(720000-640000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38110 0.95275\n"
     ]
    }
   ],
   "source": [
    "# latex4\n",
    "count=0\n",
    "for i in range(720000,760000):\n",
    "    if tex_folds[i] in arxiv_all_files:\n",
    "        count += 1\n",
    "print(count,count/(760000-720000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "''.join(dct['pretext'])\n",
      "dct['image]\n"
     ]
    }
   ],
   "source": [
    "# 统计分布\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "os.chdir('/mnt/data/ai4phys/sunyu/nougat')\n",
    "with open('data/arxiv_train_data/validation.jsonl','r')as fi:\n",
    "    lines=fi.readlines()\n",
    "len_lst=[len(json.loads(line)['pretext']) for line in lines]\n",
    "len_lst = [l for l in len_lst if l>1 and l<250] \n",
    "plt.hist(len_lst, bins=5, edgecolor='black') \n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取tex_fold/train.jsonl并合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import json\n",
    "def combine_data(tex_fold,save_fold_idx='3'):\n",
    "    if os.path.exists(f'data/arxiv_all_files{save_fold_idx}/{tex_fold}/train.jsonl') and os.path.exists(f'data/arxiv_all_files{save_fold_idx}/{tex_fold}/png'):\n",
    "        with open(f'data/arxiv_all_files{save_fold_idx}/{tex_fold}/train.jsonl','r') as fi:\n",
    "            lines = fi.read()\n",
    "        for png_file in os.listdir(f'data/arxiv_all_files{save_fold_idx}/{tex_fold}/png'):\n",
    "            subprocess.run(['cp','-n',f'data/arxiv_all_files{save_fold_idx}/{tex_fold}/png/{png_file}',f'data/arxiv_train_data/png/{tex_fold}_{png_file}'])\n",
    "            # png改为相对路径\n",
    "            lines = lines.replace(f'data/arxiv_color/{tex_fold}/png/{png_file}',f'png/{tex_fold}_{png_file}')\n",
    "            # mask处理：编码为-1，在encoding时不加position_embedding\n",
    "            lines = lines.replace('[\"mask\"]','[[-1,-1],[-1,-1]]')\n",
    "        with open(f'data/arxiv_train_data/train_color{save_fold_idx}.jsonl','a') as fo:\n",
    "            fo.write(lines)\n",
    "    elif os.path.exists(f'data/arxiv_all_files{save_fold_idx}/{tex_fold}/train_black.jsonl') and os.path.exists(f'data/arxiv_all_files{save_fold_idx}/{tex_fold}/png'):\n",
    "        with open(f'data/arxiv_all_files{save_fold_idx}/{tex_fold}/train_black.jsonl','r') as fi:\n",
    "            lines = fi.read() \n",
    "        for png_file in os.listdir(f'data/arxiv_all_files{save_fold_idx}/{tex_fold}/png'):\n",
    "            subprocess.run(['cp','-n',f'data/arxiv_all_files{save_fold_idx}/{tex_fold}/png/{png_file}',f'data/arxiv_train_data/png/{tex_fold}_{png_file}'])\n",
    "            # png改为相对路径\n",
    "            lines = lines.replace(f'data/arxiv_origin/{tex_fold}/png/{png_file}',f'png/{tex_fold}_{png_file}')\n",
    "            # mask处理：编码为-1，在encoding时不加position_embedding\n",
    "            lines = lines.replace('[\"mask\"]','[[-1,-1],[-1,-1]]')\n",
    "        with open(f'data/arxiv_train_data/train_black{save_fold_idx}.jsonl','a') as fo:\n",
    "            fo.write(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor,ProcessPoolExecutor\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=8) as pool:  \n",
    "    inputs = arxiv_all_files\n",
    "    futures = pool.map(combine_data, inputs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process color lines\n",
    "import json\n",
    "import re\n",
    "save_fold_idx='2'\n",
    "with open(f'data/arxiv_train_data/train_color{save_fold_idx}.jsonl','r') as fi:\n",
    "    lines = fi.readlines()\n",
    "for i,line in enumerate(lines):\n",
    "    dct = json.loads(line)\n",
    "    for idx in range(len(dct['prompt'])):\n",
    "        if dct['prompt'][idx] != [[-1,-1],[-1,-1]]:   # 找到第一个非'mask'位置\n",
    "            break\n",
    "    # 去掉开头多余符号\n",
    "    if idx>0 and idx<len(dct['prompt'])-1:\n",
    "        if '#' in dct['pretext'][idx-1]:   # 保留标题\n",
    "            dct['prompt'] = dct['prompt'][idx-1:]\n",
    "            dct['pretext'] = dct['pretext'][idx-1:]\n",
    "        elif idx>=2 and ('#' in dct['pretext'][idx-2] or re.search(r'figure|table',dct['pretext'][idx-2],re.I)):   # 保留图表头\n",
    "            dct['prompt'] = dct['prompt'][idx-2:]\n",
    "            dct['pretext'] = dct['pretext'][idx-2:]\n",
    "        else:\n",
    "            dct['prompt'] = dct['prompt'][idx:]\n",
    "            dct['pretext'] = dct['pretext'][idx:]\n",
    "    lines[i] = json.dumps(dct)+'\\n'\n",
    "with open(f'data/arxiv_train_data/train_color{save_fold_idx}.jsonl','w') as fo:\n",
    "    fo.writelines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process black lines\n",
    "import json\n",
    "save_fold_idx='2'\n",
    "with open(f'data/arxiv_train_data/train_black{save_fold_idx}.jsonl','r') as fi:\n",
    "    lines = fi.readlines()\n",
    "for i,line in enumerate(lines):\n",
    "    dct = json.loads(line)\n",
    "    dct['pretext'] = [dct['pretext']]\n",
    "    dct['prompt'] = [dct['prompt']]\n",
    "    lines[i] = json.dumps(dct)+'\\n'\n",
    "with open(f'data/arxiv_train_data/train_black{save_fold_idx}.jsonl','w') as fo:\n",
    "    fo.writelines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct train.jsonl val.jsonl\n",
    "import random\n",
    "save_fold_idx='2'\n",
    "with open(f'data/arxiv_train_data/train_color{save_fold_idx}.jsonl','r') as fi:\n",
    "    color_lines = fi.readlines()\n",
    "with open(f'data/arxiv_train_data/train_black{save_fold_idx}.jsonl','r') as fi:\n",
    "    black_lines = fi.readlines()\n",
    "total = 2*len(color_lines)\n",
    "train,val = int(0.8*total),int(0.2*total)\n",
    "train_lines = color_lines[:int(train/2)]+black_lines[:int(train/2)]\n",
    "val_lines = color_lines[int(train/2):]+black_lines[int(train/2):int(total/2)]\n",
    "random.shuffle(train_lines)\n",
    "random.shuffle(val_lines)\n",
    "with open(f'data/arxiv_train_data/train{save_fold_idx}.jsonl','w') as fo:\n",
    "    fo.writelines(train_lines)\n",
    "with open(f'data/arxiv_train_data/validation{save_fold_idx}.jsonl','w') as fo:\n",
    "    fo.writelines(val_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270\n",
      "2944\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "save_fold_idx='3'\n",
    "os.chdir('/mnt/data/ai4phys/sunyu/nougat')\n",
    "with open(f'data/arxiv_train_data/train_color{save_fold_idx}.jsonl','r') as fi:\n",
    "    print(len(fi.readlines()))\n",
    "with open(f'data/arxiv_train_data/train_black{save_fold_idx}.jsonl','r') as fi:\n",
    "    print(len(fi.readlines()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20675438596491227"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = 182328+39586+15460\n",
    "2357/11400"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### remove useless folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127 0\n"
     ]
    }
   ],
   "source": [
    "# remove bugs\n",
    "import subprocess\n",
    "import json\n",
    "# train0.jsonl:0-34w = 9/34 = 0.26\n",
    "# train1.jsonl:34-55w = 4/21 = 0.1\n",
    "# train2.jsonl:55-76w = 0.8/21 = 0.03\n",
    "# train3.jsonl:76-97w\n",
    "save_fold_idx='3'\n",
    "color_folds=0\n",
    "black_folds=0\n",
    "for tex_fold in tex_folds[760000:970000]:\n",
    "    if os.path.exists(f'data/arxiv_all_files{save_fold_idx}/{tex_fold}'):\n",
    "        if os.path.exists(f'data/arxiv_all_files{save_fold_idx}/{tex_fold}/train.jsonl'):\n",
    "            color_folds += 1\n",
    "            continue\n",
    "        elif os.path.exists(f'data/arxiv_all_files{save_fold_idx}/{tex_fold}/train_black.jsonl'):\n",
    "            black_folds += 1\n",
    "            continue\n",
    "        # else:\n",
    "        #     os.system(f'rm -r data/arxiv_all_files{save_fold_idx}/{tex_fold}')\n",
    "print(color_folds,black_folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "bat"
    }
   },
   "outputs": [],
   "source": [
    "# remove tmp files\n",
    "find data/arxiv_color/21* -type d -exec rm -fr \"{}\" \\;\n",
    "find data/arxiv_origin/21* -type d -exec rm -fr \"{}\" \\;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
